{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T20:50:32.636188Z",
     "start_time": "2024-11-29T20:50:30.306538Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "\n",
    "# Define Modified Network (Batch Norm + Residual Connections)\n",
    "class ModifiedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 2 * 2, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        residual = self.pool(self.bn1(self.conv1(residual)))\n",
    "        x = x + residual\n",
    "        residual = x\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        residual = self.pool(self.bn2(self.conv2(residual)))\n",
    "        x = x + residual\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "def get_dataloaders(batch_size):\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "# Train and Evaluate the Model\n",
    "def train_and_evaluate(net, trainloader, testloader, optimizer, criterion, epochs, device, classes):\n",
    "    net.to(device)\n",
    "    train_loss = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=len(classes)).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss.append(running_loss / len(trainloader))\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0 for _ in range(len(classes))]\n",
    "    class_total = [0 for _ in range(len(classes))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "                class_total[label] += 1\n",
    "\n",
    "    overall_accuracy = 100 * correct / total\n",
    "    per_class_accuracy = {classes[i]: 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "                          for i in range(len(classes))}\n",
    "\n",
    "    return train_loss, overall_accuracy, per_class_accuracy"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-29T20:53:44.810560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "results = []\n",
    "# Define an objective function to be minimized.\n",
    "def objective(trial):\n",
    "    net = ModifiedNet()\n",
    "    epochs = trial.suggest_categorical('epochs', [20, 25, 30])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64, 128])\n",
    "    lr = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    optimizer_type = trial.suggest_categorical('optimizer', ['Adam'])\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    if optimizer_type == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    elif optimizer_type == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    trainloader, testloader = get_dataloaders(batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    print(f\"Running experiment: lr={lr}, batch_size={batch_size}, optimizer={optimizer_type}, \"\n",
    "          f\"loss_function={'CrossEntropy'}, architecture={'ModifiedNet'}, epochs={epochs}\")\n",
    "    start_time = time.time()\n",
    "    train_loss, overall_accuracy, per_class_accuracy = train_and_evaluate(\n",
    "        net, trainloader, testloader, optimizer, criterion, epochs, device, classes)\n",
    "    end_time = time.time()\n",
    "\n",
    "    acc = overall_accuracy\n",
    "    results.append({\n",
    "        'learning_rate': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'optimizer': optimizer_type,\n",
    "        'loss_function': 'CrossEntropy',\n",
    "        'architecture': 'ModifiedNet',\n",
    "        'epochs': epochs,\n",
    "        'train_loss': train_loss,\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'per_class_accuracy': per_class_accuracy,\n",
    "        'time_taken': end_time - start_time\n",
    "    })\n",
    "\n",
    "    return acc  # An objective value linked with the Trial object.\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")  # Create a new study.\n",
    "study.optimize(objective, n_trials=50)  # Invoke optimization of the objective function."
   ],
   "id": "1628f12145c68ad6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 21:53:44,906] A new study created in memory with name: no-name-f8a77320-671d-437d-894d-ba07f7e078dd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Running experiment: lr=0.00011536404620534518, batch_size=128, optimizer=Adam, loss_function=CrossEntropy, architecture=ModifiedNet, epochs=20\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('experiment_results_12.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"All experiments completed and results saved to 'experiment_results.json'\")"
   ],
   "id": "ecfadef626ac5530"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
